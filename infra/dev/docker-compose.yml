version: '3.8'

services:
  back:
    build: 
      context: ../../
      dockerfile: infra/dev/back/Dockerfile
    image:
      techmatch-api:local_dev
    # wait for db to spin up
    command: bash -c 'while !</dev/tcp/db/27017; do sleep 1;done; uvicorn app.main:app --host 0.0.0.0 --port 8080 --reload'
    volumes:
      - ../../back/app:/app
    ports:
      - 8080:8080
    environment:
      - ENV=TEST
    depends_on:
      - db
    pull_policy: build

  db:
    image: mongo
    volumes:
      - techmatch_db:/data/db
    expose:
      - 27017
    ports:
      - 27017:27017
    environment:
      - MONGO_INITDB_ROOT_USERNAME=techmatch
      - MONGO_INITDB_ROOT_PASSWORD=techmatch
      - MONGO_INITDB_DATABASE=techmatch

  vllm:
    image: vllm/vllm-openai:latest
    command: --model TheBloke/Mistral-7B-Instruct-v0.2-GPTQ --enable-chunked-prefill --max_model_len 16384
    ports:
      - "9000:8000"
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all # Allocate all available GPUs
              capabilities: [gpu]
    runtime: nvidia
    ipc: host
    volumes:
      - vllm_model_cache:/root/.cache/huggingface


volumes:
  techmatch_db:
  vllm_model_cache:
